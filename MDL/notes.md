# AI.pdf

## What is machine learning

It is learning by machines that requires recognition of patterns.

## Why machine learning

Humans are idiots, they can't handle repetetive tasks, so we make "work" done by machines.

Machines are just almost perfect, we can let them do the task in a perfect way and assume work done is
correct, if machine gives wrong output, there is human error in configuration, machine never makes mistakes.

Machines can be trained on terabytes of data within shorter time than what humans need to do the same.
Machines are also more scalable, and cheap long term.

## Peace

Machine + Human Expert ---> Tireless Most efficient human

## Machine learning and Automation difference

Machine learning can adapt to dynamic changes. But automation is just shear iteration.

Data technology is the ability to use various algorithms and stuff to analyse data. Since we have
so much data now.

### Unsupervised Learning

When data only contains like input and output randomly, it is upto us (algorithm designer) to analyse the data
and find out how to describe the data.

Eg: k-clustering

### Supervised Learning

When learning comes with a good description, targets or indicative signals. The goal is to find a general
rule to map input and output (like a polynomial). They also have a validation step.

Eg: Regression, Classification

Regression - predicts continuous values predictions like graphs and stocks

Classification - find appropriate class like.

### Reinforcement Learning

It has a feedback mechanism which takes care of dynamic changes. Reinforcement learning has
some sort of interaction with the environment.

Eg: Feedback and reward system shown in chimpanzee thing

### Semi-supervised learning

When it is too expensive to find a huge labelled dataset, only some part is labeled.

## History

Categories of ML algorithms:

- Logic-Based: Formal logic and hypotheses
- Statistical-Learning: Function finding and fitting, relationship between variables (popular in 90s)
- Artificial Neural Networks: Pushed aside in 80s by above, try to emulate brain. Coming back with Deep Neural Networks (2006), multilayer networks.
GPUs we good at this.
- Genetic Algorithms: Popular in 90s too, try to use biological evolution like approach.

## Generalizing with data

Its the ability to learn from training data and be able to
apply those to test data. The mock tests in between called validation
samples are used to check in between training.

Machine learning is based on this generalization, where we will give it
input and output and let it decide what algorithm to apply to get a good
result.

Thus if we have enough sample data, we need not work on finding equations
that satisfy. Let Machine do it itself.

There are two types of generalization; underfitting, overfitting.

## Overfitting

When we learn more things than we should. This situation is called
high variance, because the model is not consistently built up,
and thus cannot perform well in test.
